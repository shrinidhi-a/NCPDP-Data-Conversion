{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-28T06:44:18.408465Z",
     "iopub.status.busy": "2025-04-28T06:44:18.408192Z",
     "iopub.status.idle": "2025-04-28T06:44:18.412488Z",
     "shell.execute_reply": "2025-04-28T06:44:18.411725Z",
     "shell.execute_reply.started": "2025-04-28T06:44:18.408445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set working Directory\n",
    "import os\n",
    "os.chdir('/kaggle/input/dataset/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "!wget https://synthea-open-data.s3.amazonaws.com/coherent/coherent-11-07-2022.zip -O \"dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:44:26.425075Z",
     "iopub.status.busy": "2025-04-28T06:44:26.424737Z",
     "iopub.status.idle": "2025-04-28T06:44:26.566184Z",
     "shell.execute_reply": "2025-04-28T06:44:26.565043Z",
     "shell.execute_reply.started": "2025-04-28T06:44:26.425052Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allergies.csv\tencounters.csv\t     observations.csv\tpayer_transitions.csv\n",
      "careplans.csv\timaging_studies.csv  organizations.csv\tprocedures.csv\n",
      "conditions.csv\timmunizations.csv    patients.csv\tproviders.csv\n",
      "devices.csv\tmedications.csv      payers.csv\t\tsupplies.csv\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/kaggle/working/dataset'):\n",
    "  os.mkdir('/kaggle/working/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('/kaggle/working/dataset.zip') as zf:\n",
    "  zip_dir = zf.namelist()[0]\n",
    "  zf.extractall('/kaggle/working/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "rmdir '/kaggle/working/dataset/fhir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:41:25.644164Z",
     "iopub.status.busy": "2025-04-28T06:41:25.643404Z",
     "iopub.status.idle": "2025-04-28T06:41:27.500009Z",
     "shell.execute_reply": "2025-04-28T06:41:27.499191Z",
     "shell.execute_reply.started": "2025-04-28T06:41:25.644131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.remove('/kaggle/working/dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory path\n",
    "dir_path = r\"/kaggle/working/dataset/dicom\"\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    \n",
    "    # Check if it is a file (not a subdirectory)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)  # Remove the file\n",
    "        print(f\"Deleted file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:45:12.516407Z",
     "iopub.status.busy": "2025-04-28T06:45:12.516084Z",
     "iopub.status.idle": "2025-04-28T06:45:12.606377Z",
     "shell.execute_reply": "2025-04-28T06:45:12.605579Z",
     "shell.execute_reply.started": "2025-04-28T06:45:12.516381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Id   BIRTHDATE   DEATHDATE          SSN  \\\n",
      "0  8b0484cd-3dbd-8b8d-1b72-a32f74a5a846  1957-04-07         NaN  999-32-2242   \n",
      "1  b8eb8d31-1031-fb5b-e207-b9815f80744c  1975-08-16         NaN  999-70-2742   \n",
      "2  ce9bd436-6b59-0452-86a4-61f3642736bc  1945-05-11  2015-04-09  999-54-1330   \n",
      "3  6fc3e360-ae68-c411-e091-4734df51eb18  1947-12-30         NaN  999-59-9652   \n",
      "4  ce4ce4d8-d4e2-aca2-5a92-8ce703c5077a  1993-02-05         NaN  999-11-2438   \n",
      "\n",
      "     DRIVERS    PASSPORT PREFIX        FIRST          LAST SUFFIX  ...  \\\n",
      "0  S99944366  X13210523X    Mr.     Gregg522  Cummerata161    NaN  ...   \n",
      "1  S99952609  X70704838X    Mr.    Lemuel304   Rodriguez71    NaN  ...   \n",
      "2  S99979547  X86639992X    Mr.  Leonardo412      Klein929    NaN  ...   \n",
      "3  S99949959  X34069329X   Mrs.     Adelle43     Dooley940    NaN  ...   \n",
      "4  S99932651  X80439009X   Mrs.      Veta780    Spencer878    NaN  ...   \n",
      "\n",
      "                         BIRTHPLACE                   ADDRESS         CITY  \\\n",
      "0     Leominster  Massachusetts  US      648 Gutkowski Parade      Amherst   \n",
      "1                  Osaka  Osaka  JP  496 Deckow Mill Suite 32   Framingham   \n",
      "2    Marlborough  Massachusetts  US  314 Brakus Forge Unit 94  New Bedford   \n",
      "3  North Amherst  Massachusetts  US             779 Haag Loaf    Wellesley   \n",
      "4         Lowell  Massachusetts  US     222 Fisher Dam Apt 74  New Bedford   \n",
      "\n",
      "           STATE            COUNTY     ZIP        LAT        LON  \\\n",
      "0  Massachusetts  Hampshire County     NaN  42.392261 -72.479152   \n",
      "1  Massachusetts  Middlesex County  1702.0  42.263233 -71.481261   \n",
      "2  Massachusetts    Bristol County  2744.0  41.665030 -70.914507   \n",
      "3  Massachusetts    Norfolk County  2457.0  42.311830 -71.286312   \n",
      "4  Massachusetts    Bristol County  2747.0  41.671645 -70.914871   \n",
      "\n",
      "  HEALTHCARE_EXPENSES HEALTHCARE_COVERAGE  \n",
      "0          1318721.22             4100.44  \n",
      "1             9089.75                0.00  \n",
      "2           230547.34             5821.16  \n",
      "3          1568950.96             8597.39  \n",
      "4           615324.99             9184.78  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/kaggle/input/dataset/csv/patients.csv')\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:47:32.332725Z",
     "iopub.status.busy": "2025-04-28T06:47:32.332363Z",
     "iopub.status.idle": "2025-04-28T06:47:32.534771Z",
     "shell.execute_reply": "2025-04-28T06:47:32.534055Z",
     "shell.execute_reply.started": "2025-04-28T06:47:32.332699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    data = []\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)  # Automatically uses headers as keys\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json('/kaggle/input/dataset/csv/patients.csv', '/kaggle/working/output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:49:20.322987Z",
     "iopub.status.busy": "2025-04-28T06:49:20.322686Z",
     "iopub.status.idle": "2025-04-28T06:49:20.447532Z",
     "shell.execute_reply": "2025-04-28T06:49:20.446874Z",
     "shell.execute_reply.started": "2025-04-28T06:49:20.322969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_with_id_as_key(csv_file_path, json_file_path):\n",
    "    data = {}\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            record_id = row.pop('Id')  # Take out 'Id' and use as key\n",
    "            data[record_id] = row\n",
    "\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json_with_id_as_key('/kaggle/input/dataset/csv/patients.csv', '/kaggle/working/output.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:53:04.670078Z",
     "iopub.status.busy": "2025-04-28T06:53:04.669730Z",
     "iopub.status.idle": "2025-04-28T06:53:04.810763Z",
     "shell.execute_reply": "2025-04-28T06:53:04.810052Z",
     "shell.execute_reply.started": "2025-04-28T06:53:04.670055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_with_patient_details(csv_file_path, json_file_path):\n",
    "    data = {}\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            record_id = row.pop('Id')  # Extract the 'Id' key\n",
    "            data[record_id] = {\"patient_details\": row}  # Wrap patient info\n",
    "\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json_with_patient_details('/kaggle/input/dataset/csv/patients.csv', '/kaggle/working/patient_details_output.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T09:17:45.522383Z",
     "iopub.status.busy": "2025-04-28T09:17:45.522079Z",
     "iopub.status.idle": "2025-04-28T09:17:45.717039Z",
     "shell.execute_reply": "2025-04-28T09:17:45.715589Z",
     "shell.execute_reply.started": "2025-04-28T09:17:45.522360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def combine_patient_and_allergies(patient_csv, allergies_csv, output_json):\n",
    "    patients = {}\n",
    "    \n",
    "    # Load patient details\n",
    "    with open(patient_csv, mode='r', newline='', encoding='utf-8') as pfile:\n",
    "        reader = csv.DictReader(pfile)\n",
    "        for row in reader:\n",
    "            patient_id = row.pop('Id')\n",
    "            patients[patient_id] = {\n",
    "                \"patient_details\": row,\n",
    "                \"allergies\": []\n",
    "            }\n",
    "\n",
    "    # Load allergies and attach to patients\n",
    "    with open(allergies_csv, mode='r', newline='', encoding='utf-8') as afile:\n",
    "        reader = csv.DictReader(afile)\n",
    "        for row in reader:\n",
    "            patient_id = row.pop('PATIENT')\n",
    "            if patient_id in patients:\n",
    "                patients[patient_id][\"allergies\"].append(row)\n",
    "            else:\n",
    "                # Optional: handle if allergy refers to unknown patient\n",
    "                pass\n",
    "\n",
    "    # Save to output JSON\n",
    "    with open(output_json, mode='w', encoding='utf-8') as outfile:\n",
    "        json.dump(patients, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "combine_patient_and_allergies('/kaggle/input/dataset/csv/patients.csv', '/kaggle/input/dataset/csv/allergies.csv', 'patient_allergies.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T09:23:53.171618Z",
     "iopub.status.busy": "2025-04-28T09:23:53.171316Z",
     "iopub.status.idle": "2025-04-28T09:23:53.689984Z",
     "shell.execute_reply": "2025-04-28T09:23:53.689043Z",
     "shell.execute_reply.started": "2025-04-28T09:23:53.171597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def combine_patient_allergies_careplans(patient_csv, allergies_csv, careplans_csv, output_json):\n",
    "    patients = {}\n",
    "    \n",
    "    # Load patient details\n",
    "    with open(patient_csv, mode='r', newline='', encoding='utf-8') as pfile:\n",
    "        reader = csv.DictReader(pfile)\n",
    "        for row in reader:\n",
    "            patient_id = row['Id']   # Do NOT pop\n",
    "            patients[patient_id] = {\n",
    "                \"patient_details\": row,  # Keep full row including Id\n",
    "                \"allergies\": [],\n",
    "                \"careplans\": []\n",
    "            }\n",
    "\n",
    "    # Load allergies and attach to patients\n",
    "    with open(allergies_csv, mode='r', newline='', encoding='utf-8') as afile:\n",
    "        reader = csv.DictReader(afile)\n",
    "        for row in reader:\n",
    "            patient_id = row['PATIENT']  # Do NOT pop\n",
    "            if patient_id in patients:\n",
    "                patients[patient_id][\"allergies\"].append(row)\n",
    "\n",
    "    # Load careplans and attach to patients\n",
    "    with open(careplans_csv, mode='r', newline='', encoding='utf-8') as cfile:\n",
    "        reader = csv.DictReader(cfile)\n",
    "        for row in reader:\n",
    "            patient_id = row['PATIENT']  # Do NOT pop\n",
    "            if patient_id in patients:\n",
    "                patients[patient_id][\"careplans\"].append(row)\n",
    "\n",
    "    # Save to output JSON\n",
    "    with open(output_json, mode='w', encoding='utf-8') as outfile:\n",
    "        json.dump(patients, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "combine_patient_allergies_careplans('/kaggle/input/dataset/csv/patients.csv', '/kaggle/input/dataset/csv/allergies.csv', '/kaggle/input/dataset/csv/careplans.csv', 'patients_allergies_careplans.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T09:25:36.732949Z",
     "iopub.status.busy": "2025-04-29T09:25:36.731913Z",
     "iopub.status.idle": "2025-04-29T09:26:24.941754Z",
     "shell.execute_reply": "2025-04-29T09:26:24.940822Z",
     "shell.execute_reply.started": "2025-04-29T09:25:36.732912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "patient_csv = '/kaggle/input/dataset/csv/patients.csv'\n",
    "allergies_csv = '/kaggle/input/dataset/csv/allergies.csv'\n",
    "careplans_csv = '/kaggle/input/dataset/csv/careplans.csv'\n",
    "conditions_csv = '/kaggle/input/dataset/csv/conditions.csv'\n",
    "devices_csv = '/kaggle/input/dataset/csv/devices.csv'\n",
    "encounters_csv = '/kaggle/input/dataset/csv/encounters.csv'\n",
    "imaging_studies_csv = '/kaggle/input/dataset/csv/imaging_studies.csv'\n",
    "immunizations_csv = '/kaggle/input/dataset/csv/immunizations.csv'\n",
    "medications_csv = '/kaggle/input/dataset/csv/medications.csv'\n",
    "observations_csv = '/kaggle/input/dataset/csv/observations.csv'\n",
    "#organizations_csv = '/kaggle/input/dataset/csv/organizations.csv'\n",
    "payer_transitions_csv = '/kaggle/input/dataset/csv/payer_transitions.csv'\n",
    "#payers_csv = '/kaggle/input/dataset/csv/payers.csv'\n",
    "procedures_csv = '/kaggle/input/dataset/csv/procedures.csv'\n",
    "#providers_csv = '/kaggle/input/dataset/csv/providers.csv'\n",
    "#supplies_csv = '/kaggle/input/dataset/csv/supplies.csv'\n",
    "\n",
    "output_json = 'final_output.json'\n",
    "\n",
    "patients = {}\n",
    "    \n",
    "with open(patient_csv, mode='r', newline='', encoding='utf-8') as pfile:\n",
    "    reader = csv.DictReader(pfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['Id']\n",
    "        patients[patient_id] = {\n",
    "            \"patient_details\": row,\n",
    "            \"allergies\": [],\n",
    "            \"careplans\": [],\n",
    "            \"conditions\" : [],\n",
    "            \"devices\" : [],\n",
    "            \"encounters\" : [],\n",
    "            \"imaging_studies\" : [],\n",
    "            \"immunizations\" : [],\n",
    "            \"medications\" : [],\n",
    "            \"observations\" : [],\n",
    "            \"payer_transitions\" : [],\n",
    "            \"procedures\" : []\n",
    "        }\n",
    "\n",
    "#allergies_csv\n",
    "with open(allergies_csv, mode='r', newline='', encoding='utf-8') as afile:\n",
    "    reader = csv.DictReader(afile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"allergies\"].append(row)\n",
    "\n",
    "#careplans_csv\n",
    "with open(careplans_csv, mode='r', newline='', encoding='utf-8') as bfile:\n",
    "    reader = csv.DictReader(bfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"careplans\"].append(row)\n",
    "\n",
    "#conditions_csv\n",
    "with open(conditions_csv, mode='r', newline='', encoding='utf-8') as cfile:\n",
    "    reader = csv.DictReader(cfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"conditions\"].append(row)\n",
    "\n",
    "#devices_csv\n",
    "with open(devices_csv, mode='r', newline='', encoding='utf-8') as dfile:\n",
    "    reader = csv.DictReader(dfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"devices\"].append(row)\n",
    "\n",
    "#encounters_csv\n",
    "with open(encounters_csv, mode='r', newline='', encoding='utf-8') as efile:\n",
    "    reader = csv.DictReader(efile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"encounters\"].append(row)\n",
    "\n",
    "#imaging_studies_csv\n",
    "with open(imaging_studies_csv, mode='r', newline='', encoding='utf-8') as ffile:\n",
    "    reader = csv.DictReader(ffile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"imaging_studies\"].append(row)\n",
    "\n",
    "#immunizations_csv\n",
    "with open(immunizations_csv, mode='r', newline='', encoding='utf-8') as gfile:\n",
    "    reader = csv.DictReader(gfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"immunizations\"].append(row)\n",
    "\n",
    "#medications_csv\n",
    "with open(medications_csv, mode='r', newline='', encoding='utf-8') as hfile:\n",
    "    reader = csv.DictReader(hfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"medications\"].append(row)\n",
    "\n",
    "#observations_csv\n",
    "with open(observations_csv, mode='r', newline='', encoding='utf-8') as ifile:\n",
    "    reader = csv.DictReader(ifile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"observations\"].append(row)\n",
    "\n",
    "#payer_transitions_csv\n",
    "with open(payer_transitions_csv, mode='r', newline='', encoding='utf-8') as jfile:\n",
    "    reader = csv.DictReader(jfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"payer_transitions\"].append(row)\n",
    "\n",
    "#procedures_csv\n",
    "with open(procedures_csv, mode='r', newline='', encoding='utf-8') as kfile:\n",
    "    reader = csv.DictReader(kfile)\n",
    "    for row in reader:\n",
    "        patient_id = row['PATIENT']\n",
    "        if patient_id in patients:\n",
    "            patients[patient_id][\"procedures\"].append(row)\n",
    "            \n",
    "with open(output_json, mode='w', encoding='utf-8') as outfile:\n",
    "    json.dump(patients, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7271874,
     "sourceId": 11596011,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
